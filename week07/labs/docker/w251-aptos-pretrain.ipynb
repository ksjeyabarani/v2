{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "#print(os.listdir(\"../input\"))\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "#import seaborn as sns\n",
    "import random\n",
    "from apex import amp\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "seed_everything(1234)\n",
    "lr          = 1e-4\n",
    "efficientnet_arch = 'efficientnet-b4'\n",
    "IMG_SIZE    = EfficientNet.get_image_size(efficientnet_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train      = '/data/kaggle/aptos/train/images/'\n",
    "train_2015      = '/data/kaggle/aptos/trainold/resized_train_cropped/'\n",
    "#valid      = '/data/aptos/train/images/'\n",
    "test       = '/data/kaggle/aptos/test/images/'\n",
    "\n",
    "# train_csv  = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "\n",
    "## train_csv = pd.read_csv(\"/data/aptos/train.csv\")\n",
    "train_csv = pd.read_csv(\"/data/kaggle/aptos/trainboth.csv\")\n",
    "#valdata = pd.read_csv(\"/data/aptos/valboth.csv\")\n",
    "test_df = pd.read_csv(\"/data/kaggle/aptos/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train      = '../input/aptos2019-blindness-detection/train_images/'\n",
    "# test       = '../input/aptos2019-blindness-detection/test_images/'\n",
    "# train_csv  = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_csv, test_size=0.1, random_state=2018, stratify=train_csv.diagnosis)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['diagnosis'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['diagnosis'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(drop=True, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_path(p):\n",
    "    p = str(p)\n",
    "    if isfile(train + p + \".png\"):\n",
    "        return train + (p + \".png\")\n",
    "    if isfile(train_2015 + p + '.jpeg'):\n",
    "        return train_2015 + (p + \".jpeg\")\n",
    "    if isfile(test + p + \".png\"):\n",
    "        return test + (p + \".png\")\n",
    "    return p\n",
    "\n",
    "def p_show(imgs, label_name=None, per_row=3):\n",
    "    n = len(imgs)\n",
    "    rows = (n + per_row - 1)//per_row\n",
    "    cols = min(per_row, n)\n",
    "    fig, axes = plt.subplots(rows,cols, figsize=(15,15))\n",
    "    for ax in axes.flatten(): ax.axis('off')\n",
    "    for i,(p, ax) in enumerate(zip(imgs, axes.flatten())): \n",
    "        img = Image.open(expand_path(p))\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(train_df[train_df.id_code == p].diagnosis.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for p in train_df.id_code:\n",
    "    imgs.append(p)\n",
    "    if len(imgs) == 16: break\n",
    "p_show(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Code from: https://www.kaggle.com/ratthachat/aptos-updated-albumentation-meets-grad-cam\n",
    "\n",
    "def crop_image1(img,tol=7):\n",
    "    # img is image data\n",
    "    # tol  is tolerance\n",
    "        \n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.df.diagnosis.values[idx]\n",
    "        label = np.expand_dims(label, -1)\n",
    "        \n",
    "        p = self.df.id_code.values[idx]\n",
    "        p_path = expand_path(p)\n",
    "        image = cv2.imread(p_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = crop_image_from_gray(image)\n",
    "        try: \n",
    "          image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        except:\n",
    "            print(\"unable to resize image: \", p_path)\n",
    "#        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 30) ,-4 ,128)\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation((-120, 120)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "#    transforms.RandomHorizontalFlip(),\n",
    "#    transforms.RandomRotation((-120, 120)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset     = MyDataset(train_df, transform =train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=12)\n",
    "#valset       = MyDataset(val_df, transform   =train_transform)\n",
    "valset       = MyDataset(val_df, transform   =val_transform)\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset       = MyDataset(test_df, transform   =val_transform)\n",
    "test_loader   = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EfficientNet.from_name('efficientnet-b0')\n",
    "#model = EfficientNet.from_name('efficientnet-b4')\n",
    "#model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b3-5fb5a3c3.pth'))\n",
    "# model.load_state_dict(torch.load('../input/efficientnet-pytorch/efficientnet-b0-08094119.pth'))\n",
    "#model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b0-08094119.pth'))\n",
    "#model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b5-586e6cc6.pth'))\n",
    "#model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b4-e116e8b3.pth'))\n",
    "\n",
    "#in_features = model._fc.in_features\n",
    "#model._fc = nn.Linear(in_features, num_classes)\n",
    "#model.cuda()\n",
    "model = EfficientNet.from_pretrained(efficientnet_arch, num_classes=num_classes)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    model.train() \n",
    "        \n",
    "    avg_loss = 0.\n",
    "    optimizer.zero_grad()\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "        if idx > 0 and idx % 10 == 0:\n",
    "            print(\"step: \", idx, \" / \", len(train_loader))\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.float().cuda()\n",
    "        output_train = model(imgs_train)\n",
    "        loss = criterion(output_train,labels_train)\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "    return avg_loss\n",
    "\n",
    "def test_model():\n",
    "    \n",
    "    avg_val_loss = 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "            imgs_vaild, labels_vaild = imgs.cuda(), labels.float().cuda()\n",
    "            output_test = model(imgs_vaild)\n",
    "            avg_val_loss += criterion(output_test, labels_vaild).item() / len(val_loader)\n",
    "        \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfile = 'chkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_avg_loss = 100.0\n",
    "n_epochs      = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "#     print('lr:', scheduler.get_lr()[0]) \n",
    "    print('lr:', lr) \n",
    "    start_time   = time.time()\n",
    "    avg_loss     = train_model(epoch)\n",
    "    avg_val_loss = test_model()\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
    "        epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "    \n",
    "    if avg_val_loss < best_avg_loss:\n",
    "        best_avg_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), mfile)\n",
    "    \n",
    "#    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), mfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model.load_state_dict(torch.load(mfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next time this needs to go\n",
    "model = EfficientNet.from_name('efficientnet-b4')\n",
    "in_features = model._fc.in_features\n",
    "model._fc = nn.Linear(in_features, num_classes)\n",
    "model.load_state_dict(torch.load(mfile))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the best score\n",
    "# test_model()\n",
    "model.eval()\n",
    "outputlist = []\n",
    "avg_val_loss = 0.\n",
    "with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # move to GPU\n",
    "        \n",
    "            data, target = data.cuda(), target.float().cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            outputlist.append(output)\n",
    "            avg_val_loss += criterion(output, target).item() / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_outputs(preds):\n",
    "    finalpreds = []\n",
    "    for batch in preds:\n",
    "        for arr in batch:\n",
    "            for num in arr:\n",
    "                finalpreds.append(num.cpu().item())\n",
    "    return finalpreds\n",
    "outputlist=format_outputs(outputlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import os\n",
    "#import scipy as sp\n",
    "#from functools import partial\n",
    "#from sklearn import metrics\n",
    "#from collections import Counter\n",
    "#import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = val_df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "def quadratic_kappa(y_hat, y):\n",
    "    return cohen_kappa_score(np.round(y_hat), y, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(outputlist, targets)\n",
    "coefficients = optR.coefficients()\n",
    "print(coefficients)\n",
    "valid_predictions = optR.predict(outputlist, coefficients)\n",
    "valid_predictions\n",
    "quadratic_kappa(valid_predictions, targets)\n",
    "# test_predictions = optR.predict(test_predictions, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
